# Phase 03: Experiments (autonomy + memory awareness)

## Goal

Extend the AGI with experimental features that make it more autonomous and self-aware: autonomous chaining (list_dir then read first file in one tick), "what do you remember?" (respond from recalled semantic/episodic), and internal thought (reasoner returns thought; core stores in working memory).

## Deliverables

### 1. Reasoner extensions (`src/agi/reasoner.py`)

- **"What do you remember?"**: When input is "what do you remember?", "summarize", "recall", "memory", suggest respond with formatted recalled summary (semantic facts + episodic events).
- **Chaining**: When state has `last_observation` (from a previous act in the same tick), if it's list_dir with entries, suggest read_file on first file-like entry; else suggest respond with summary.
- **Recalled semantic in beliefs**: Include recalled semantic facts in beliefs["facts"] so the agent "remembers" learned facts.
- **Thought**: Return a "thought" string (e.g. "User requested list_dir; I will run it.") for interpretability.

### 2. Core extensions (`src/agi/core.py`)

- **Store thought**: After reason, store reason_out["thought"] in working memory as last_thought.
- **Autonomous chaining**: Up to 2 acts per tick. After first act, if result is list_dir with entries (no response yet), set last_observation, reason again, plan; if next_step is read_file, do second act; else respond with entries and halt.

### 3. Verification

- Existing tests (core, reasoner) pass.
- Manual: "list directory src" can chain to read first file in src; "what do you remember?" returns recalled summary.

## Notes

- Chaining is experimental: one user message can trigger list_dir then read first file in the same tick.
- Thought is stored in working memory for future use (e.g. recall, debugging, or LLM context).
